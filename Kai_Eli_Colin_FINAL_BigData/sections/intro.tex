As of 2019, it was estimated that more than five billion people have cell phones and over half of these devices are smartphones. The amount of data generated from these devices is enormous; most of them are equipped with a myriad of sensors, e.g.\ accelerometer, gyroscopes, magnetometers, and so forth \cite{ferrari2019hand}. The information from these sensors has enabled the study of Human Activity Recognition (HAR), i.e.\ the determination of what physical activity a person is performing (for example, HAR determines if a person is walking, running, sitting, standing, falling, etc.) based upon the outputs of these sensors. HAR has a variety of applications. For instance, in healthcare, determining when the elderly have had a potentially-devastating fall; another, in sports, where techniques can be refined to perfection; in cybersecurity, for  continuous-user authentication by keeping track of who is physically manipulating the smartphone; and, finally, in generating a more secure biometric key which are harder to spoof than the traditional fingerprint and iris scanners \cite{malekzadeh2018protecting, saeed2019multi}.

The sheer number of smart phones opens the door to big data approaches. Often, HAR data is non-linear so typical machine-learning techniques---such as support vector machines (SVM), principal component analysis (PCA), etc.---which rely on linearity for analysis,  do not perform as well as deep neural networks which are not constrained linearly \cite{sitova2015hmog,saeed2019multi, he2016deep, ferrari2019homogenization}. Neural network models, with complicated, unintuitive architectures, merely provides an output from a set of inputs and allow for very little in the way of understanding the fundamental aspects of the problem. Deep neural networks also rely on vast amounts of high-fidelity, labeled training data, which often is not feasible to gather for most problems. As a result, neural networks are often over-fit, and their accuracy can be highly dependent on the specific conditions in which the data was taken (e.g.\ data taken in controlled conditions).

Our hope is to improve the performance of traditional machine-learning methods in the context of HAR by accurately accounting for the inherent non-linearity of the data through extensive preprocessing. This would both allow for higher performance and elucidate what our algorithm is actually doing to classify activities. The hope is that we will perform better than the both the supervised and unsupervised machine-learning methods used in the other papers with a stretch goal of approaching neural network performance.

With this in mind, we have a simple---albeit rather difficult---goal. By combining multiple datasets, we aim to develop a robust algorithm to classify six activities---walking up stairs, walking down stairs, walking, jogging, sitting, and standing---using only the accelerometer (and maybe gyroscopic) data recorded by various smartphones. To measure the accuracy of our classifiers, we will cross-validate across users, so that we \textit{never} predict a user's activity using a classifier already trained on that user. By combining multiple datasets for training and testing our model, with different sensor types, sampling rates etc., we are hoping to improve the reliability of our classifier in novel situations. If we are able to perform well, despite the fundamental differences in the datasets, then our model may be robust enough for real-life use.
